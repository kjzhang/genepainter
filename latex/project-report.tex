%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proceedings of the National Academy of Sciences (PNAS)
% LaTeX Template
% Version 1.0 (19/5/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% The PNAStwo class was created and is owned by PNAS:
% http://www.pnas.org/site/authors/LaTex.xhtml
% This template has been modified from the blank PNAS template to include
% examples of how to insert content and drastically change commenting. The
% structural integrity is maintained as in the original blank template.
%
% Original header:
%% PNAStmpl.tex
%% Template file to use for PNAS articles prepared in LaTeX
%% Version: Apr 14, 2008
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

%------------------------------------------------
% BASIC CLASS FILE
%------------------------------------------------

%% PNAStwo for two column articles is called by default.
%% Uncomment PNASone for single column articles. One column class
%% and style files are available upon request from pnas@nas.edu.

%\documentclass{pnasone}
\documentclass{pnastwo}

%------------------------------------------------
% POSITION OF TEXT
%------------------------------------------------

%% Changing position of text on physical page:
%% Since not all printers position
%% the printed page in the same place on the physical page,
%% you can change the position yourself here, if you need to:

% \advance\voffset -.5in % Minus dimension will raise the printed page on the 
                         %  physical page; positive dimension will lower it.

%% You may set the dimension to the size that you need.

%------------------------------------------------
% GRAPHICS STYLE FILE
%------------------------------------------------

%% Requires graphics style file (graphicx.sty), used for inserting
%% .eps/image files into LaTeX articles.
%% Note that inclusion of .eps files is for your reference only;
%% when submitting to PNAS please submit figures separately.

%% Type into the square brackets the name of the driver program 
%% that you are using. If you don't know, try dvips, which is the
%% most common PC driver, or textures for the Mac. These are the options:

% [dvips], [xdvi], [dvipdf], [dvipdfm], [dvipdfmx], [pdftex], [dvipsone],
% [dviwindo], [emtex], [dviwin], [pctexps], [pctexwin], [pctexhp], [pctex32],
% [truetex], [tcidvi], [vtex], [oztex], [textures], [xetex]

\usepackage{graphicx}

%------------------------------------------------
% OPTIONAL POSTSCRIPT FONT FILES
%------------------------------------------------

%% PostScript font files: You may need to edit the PNASoneF.sty
%% or PNAStwoF.sty file to make the font names match those on your system. 
%% Alternatively, you can leave the font style file commands commented out
%% and typeset your article using the default Computer Modern 
%% fonts (recommended). If accepted, your article will be typeset
%% at PNAS using PostScript fonts.

% Choose PNASoneF for one column; PNAStwoF for two column:
%\usepackage{PNASoneF}
%\usepackage{PNAStwoF}

%------------------------------------------------
% ADDITIONAL OPTIONAL STYLE FILES
%------------------------------------------------

%% The AMS math files are commonly used to gain access to useful features
%% like extended math fonts and math commands.

\usepackage{amssymb,amsfonts,amsmath}
\usepackage[]{algorithm2e}

%------------------------------------------------
% OPTIONAL MACRO FILES
%------------------------------------------------

%% Insert self-defined macros here.
%% \newcommand definitions are recommended; \def definitions are supported

%\newcommand{\mfrac}[2]{\frac{\displaystyle #1}{\displaystyle #2}}
%\def\s{\sigma}

%------------------------------------------------
% DO NOT EDIT THIS SECTION
%------------------------------------------------

%% For PNAS Only:
\contributor{CS289, Harvard University}
\url{Wang and Zhang}
\copyrightyear{2014}
\volume{Spring}
\issuedate{}
\issuenumber{}

%----------------------------------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------------------------------
%	TITLE AND AUTHORS
%----------------------------------------------------------------------------------------

\title{Genetic Algorithms } % For titles, only capitalize the first letter

%------------------------------------------------

%% Enter authors via the \author command.  
%% Use \affil to define affiliations.
%% (Leave no spaces between author name and \affil command)

%% Note that the \thanks{} command has been disabled in favor of
%% a generic, reserved space for PNAS publication footnotes.

%% \author{<author name>
%% \affil{<number>}{<Institution>}} One number for each institution.
%% The same number should be used for authors that
%% are affiliated with the same institution, after the first time
%% only the number is needed, ie, \affil{number}{text}, \affil{number}{}
%% Then, before last author ...
%% \and
%% \author{<author name>
%% \affil{<number>}{}}

%% For example, assuming Garcia and Sonnery are both affiliated with
%% Universidad de Murcia:
%% \author{Roberta Graff\affil{1}{University of Cambridge, Cambridge,
%% United Kingdom},
%% Javier de Ruiz Garcia\aff	il{2}{Universidad de Murcia, Bioquimica y Biologia
%% Molecular, Murcia, Spain}, \and Franklin Sonnery\affil{2}{}}

\author{Andrew Wang\affil{1}{awang@college.harvard.edu}
\and
Kevin Zhang\affil{2}{kzhang@college.harvard.edu}}

\contributor{Computer Science 289 Final Project}

%----------------------------------------------------------------------------------------

\maketitle % The \maketitle command is necessary to build the title page

\begin{article}

%----------------------------------------------------------------------------------------
%	ABSTRACT, KEYWORDS AND ABBREVIATIONS
%----------------------------------------------------------------------------------------

\begin{abstract}
We review the mathematical basis behind PDE-based image editing, focusing on methods of image interpolation for inpainting, including smoothing, linear diffusion, and nonlinear diffusion. Additionally, we implement a PDE-based image compression and decompression scheme. We investigate random sampling and a recursive tree-based sampling method for selecting pixels to decompress.


\end{abstract}

%------------------------------------------------

\keywords{Genetic Algorithms | Image Processing | Hill Climbing} % When adding keywords, separate each term with a straight line: |

%------------------------------------------------

%% Optional for entering abbreviations, separate the abbreviation from
%% its definition with a comma, separate each pair with a semicolon:
%% for example:
%% \abbreviations{SAM, self-assembled monolayer; OTS,
%% octadecyltrichlorosilane}

% \abbreviations{}
\abbreviations{BTTC, B-tree triangular coding; MSE, mean-squared error}

%----------------------------------------------------------------------------------------
%	PUBLICATION CONTENT
%----------------------------------------------------------------------------------------

%% The first letter of the article should be drop cap: \dropcap{} e.g.,
%\dropcap{I}n this article we study the evolution of ''almost-sharp'' fronts

\section{Introduction}

\dropcap{O}ne of the most popular fields of image processing is the field of applying filters to images to render a different look or feeling. Popularized by Photoshop and Instagram, most of these filters concentrate and focus on things such as changing the contrast, exposure, or rendering the entire image in a different style. However, these algorithms often require fine tuning and in the cases of more artistic filters, are unable to provide a sense of realism as to how the piece was produced. In particular, in this paper we are interested in designing and testing an algorithm that attempts to tackle the problem of rendering photos in an impressionist manner like the works of Monet, Renoir, etc.  The impressionist paintings are distinct in that they use relatively small and thin brush strokes to depict the entire painting. These strokes are very visible on the painting and create an atmosphere of open composition which depicts light in expression over time.

%The most popular lossy compression approach for images uses wavelet or discrete cosine transforms.  
Hence, the project that we are interested in pursuing is creating impressionist versions of drawings through a genetic algorithm. Given an image, we would like to find the best matching image composed of $n$ strokes. The strokes themselves are composed of splines with $k$ points, $h$ hue, $o$ opacity, and $t$ thickness. The fitness function $f$ would then measure how different the variant (or child) is from the actual image. A simple example of such a variant would be $f$ that calcualtes the $L_2$-norm of the actual and evolved image.

While the given fitness function would suggest that the evolved image should look very close to the actual image, we hope that by limiting the number of strokes we can achieve an impresssionist effect. The idea is that if we want a certain effect or nature to be very present in the final product, we can potentially achieve this by making the building block have the attribute and additionally limit the number of blocks to prevent the effect from being saturated..

\section{Background and Related Work}
Unfortuantely, the topic of interest has very little literature. As far as we know, the only similar work is the Genetic Programming: Evolution of Mona Lisa work by Roger Alsing. Essentially, the work took a DNA string(each gene represents a polygon with a certain color) and continued to mutate the DNA string closer to the actual image.  At each step, the mutated child would be compared to the actual image and if it had a higher fitness function ($L_2$-norm), the child would succeed the parent.  This simple process yielded a fairly acceptable rendering of the Mona Lisa with minor artifacts. Also, we note that the Mona Lisa didn't really use genetic algorithms to their full potential, since a population of images wasn't used. A single image was mutated closer to the actual image with each step, so the work is more similar to hill-climbing. We feel that by using a population and incorporating crossover methods, we can reach an optimum in much fewer steps, although computation is more expensive.

A few things to note about the experiment are that it took a significant amount of time (most likely due to 0 cross overs and only a population size of two) but yielded a reasonable result. As a result, we are fairly certain that in our case, we should be able to yield a similar result at the very least. That is, if we use two points, we would have rectangles and hence it would not be surprising to get a decent result.

In other works that attempted to replicate Roger Alsing's work, more proper genetic algorithim approaches were taken which accounted for adjustable population size, selection, DNA mixing, etc. These approaches were able to achieve a faster convergence to the work of the Mona Lisa but the authors chose not to determine the amount of time necessary for a visually unindiscernible image to be generated. These works demonstrate our belief that adding crossovers and that of the like result in faster convergence then the straight forward hill climbing strategy of Alsing.

Finally, we would like to note that in contrast to these works we will not be mutating polygons. This differents in the uniformity of space covered as well as the distribution of the space. For example, given that we choose to use less than 4 to 5 points per spline, the space that we cover may be rather thin and limited. Essentially, the point we would like to elaborate is that while the focus of the problem remains similar, the problem space is extremely different.


\section{Sampling for image compression}

In order to compress the image, we will need to select a subset of $n_p$ pixels that will then be used to reconstruct the image.  Two naive approaches are to select $n_p$ pixels in a uniform grid or to select $n_p$ random pixels from the image. However, these approaches are inefficient as many of the chosen pixels will be located in areas without important features. Instead, selecting pixels from edges within the image where the color gradient is changing quickly is more efficient, since those features must be identified to accurately reconstruct the image.  However, storing store all the edges is impractical, so we will therefore look for corners, i.e. the points where the edges change the most. The resulting sample set will be the pixels that represent the most change in the image.

\subsection{B-tree triangular coding}
To identify the important corners within the image, we implement binary-tree triangular coding (BTTC), developed by Distasi et al \cite{distasi}, which recursively decomposes the image into right-angled triangles. The BTTC algorithm represents an image $u$ as a surface $A = \{(x,y,c) | c = u(x,y)\}$.  The goal is to approximate $A$ by a discrete surface $B = \{(x,y,d) | d = G(x,y)\}$ with a finite-set of polyhedrons.  Each polyhedron has a right-angle triangle on the XY plane (PRAT) and an upper face right-angle triangle approximating $A$ (URAT).

As illustration, let $T$ be a PRAT of vertices $P_1 = (x_1,y_1)$, $P_2 = (x_2, y_2)$, and $P_3 = (x_3,y_3)$.  If $c_i = u(x_i,y_i)$, then the $(x_i, y_i, c_i)$ are points in $A$ for $i=\{1,2,3\}$ that define the URAT associated with $T$.  BTTC then approximates $u$ within $T$ with the function $G$ that uses linear interpolation
\begin{equation}
G(x,y) = c_1 + \alpha(c_2 - c_1) + \beta(c_3 -c_1)
 \label{G}
\end{equation}
where $\alpha$ and $\beta$ are defined as
$$\alpha = \frac{(x-x_1)(y_3 - y_1) - (y-y_1)(x_3-x_1)}{(x_2-x_1)(y_3 - y_1) - (y_2-y_1)(x_3-x_1)}$$
$$\beta = \frac{(x_2-x_1)(y - y_1) - (y_2-y_1)(x-x_1)}{(x_2-x_1)(y_3 - y_1) - (y_2-y_1)(x_3-x_1)}$$
The approximation has error defined as distance between $u(x,y) \in \mathbb{R}^3$ and $G(x,y)\in \mathbb{R}^3$
$$\text{err}(x,y) = ||u(x,y) - G(x,y)||_2$$
and we determine if the approximation is sufficient with a error condition based on threshold $\epsilon > 0$
$$\text{err}(x,y) \leq \epsilon$$

If the condition does not hold for $T$, the PRAT of $T$ is divided into two right-angle triangles.  The subdivision procedure is reiterated until the condition holds for all PRATs, and the resulting structure is a binary-tree where each node represents a triangle with either two or zero children.\\

The overall algorithm for BTTC is as follows:
\begin{enumerate}
\item \emph{Initialize the set of PRATS}. 

Set $L = \emptyset$.
\item \emph{Intialize the first two PRATS}. 

Set $T_1 = \{(1,1),(1,m),(m,1)\}$ and 

$T_2 = \{(m,m),(m,1),(1,m)\}$
\item Push $T_1$ and $T_2$ onto the stack.
\item Pop the PRAT $T$ from the stack, with vertices\\
$P_1 = (x_1,y_1)$, $P_2 = (x_2, y_2)$, and $P_3 = (x_3,y_3)$.

Set $c_i = u(x_i,y_i)$ to define the URAT of $T$.

\item For each point $(x,y) \in T$, calculate $G(x,y)$ and $err(x,y)$.

If $err(x,y) \leq \varepsilon$ for all points, go to step 7.

\item \emph{Divide $T$ into two PRATs}

Set $P_M = (P_2 + P_3)/2$.

Set $T_1 = \{P_M, P_1, P_2\}$ and $T_2 = \{P_M,P_3,P_1\}$.

Go to step 3.

\item Insert $T$ into $L$.

\item If the stack is empty, then stop.  Otherwise, go to Step 4.
\end{enumerate}

The algorithm requires the image dimensions to be square with edge size $2^m+1$ for some $m$. If the image size is invalid, then each sides are padded by zeros to one plus the next power of two. The runtime complexity for the algorithm is an efficient $O(n \log n)$ for an image with $n$ pixels, and we demonstrate that BTTC is able to accurately choose points in areas of high curvature, since the mean squared error (MSE) is bounded by $\epsilon^2$.  For additional details, see \cite{distasi}.

\section{Metrics for Similarity}
The metric by which we determine similarity in this paper are the $L_1$-norm and the $L_2$-norm. Essentially, given image A and image B, the fitness function for the $L_1$-norm variant would be defined as
\[ \sum\limits_{i,j} |A_{i,j} - B_{i,j}| \]
which intuitively simply means that the fitness function accounts for error, weighting the color offset for each pixel the same.
For the $L_2$-norm version of the fitness function, we have
\[ \sum\limits_{i,j} (A_{i,j} - B_{i,j})^2 \]
which instead weights pixel offsets that are far off much more. While we do test both metrics for similarity, it may seem intuitively clear why most image processing algorithms use the $L_2$-norm. Rather thann weight all offsets the same, the farther a single pixel is off, the more heavily it is weighted. For example, if an image is off by one shade of red throughout the entire image, it is considered better than an image that has a large large color offset for a small region of the image.

\section{Rendering the Image}
To render the image of splines, the following method were considered. For every given point in the image, we determined the closest point on each and every spline curve to the point using the methods detailed by Wang et. al \cite{wang}. Using this distance and the width of the spline, we can determine whether the pixel would have been covered by a certain spline. Testing this method via Python, we determined that over 50 splines and an image of size 256 x 256, each complete rendering of the image took approximately 3 seconds on a 4.4Ghz i-3570k. Further testing yielded that the bottleneck factor was not the $L_2$-norm being computed but rather the actual rendering of the spline. In essence, for an image of size $MN$ with $K$ splines, it required $MNK$ iterations of the composite Newton method described in the paper.

The next approach to achieve rendering in a computatably feasible manner was to draw the splines and then dilate the pixels of the spline. While it appears to have the same worst case performance, through the use of optimized packages, the rendering was achieved in approximately 0.01 seconds. We deemed that this computation time was sufficient for our purposes. 

\section{General Approach}
Our general approach was to create a set of strokes $s$, each which represented a spline with a certain width, color, and opacity. These strokes would undergo the process of evolution as dictated by the genetic algorithm which would ultimately result in a set of improved strokes $\hat{s}$ that would resemble the original image.

\subsection{Genes}
The representation of the genes in this work was the stroke. These genes contained a list of points with x,y coordinates, determining each location of a sequential point for the spline. We restricted the number of points to be greater than 2 but less than 5. In the case that the points numbered from 2 to 3, the points did not actually form a spline and as a result, were connected via a straight line. We limited the number of points to be less than 5 to avoid resulting in a stroke that covered the entire image. All the points were generated via a random uniform distribution whose ranges were capped by the maximum width and maximum height of the image.  Additionally, the gene contained information about the color in the standard RGB format with a range of integer values of 0 to 255 for each color. All 3 channels had their values generated initially via a random uniform distribution. To deal with the problem of layering strokes, each stroke was also assigned an alpha value to add the factor of opacity into the painting. The alpha value was contained between the values of 0.25 and 1.0. The alpha value was also generated initially via a random uniform distribution. Finally, to account for the width of the stroke, a width factor was included in the stroke. To avoid drawing too thin or too wide, the width of the stroke was generate uniformly between 5 to 15 percent of the minimum of the height and width of the image.

\subsection{Population and Survival Policy}
Unlike the Alsing work, we choose to keep both an adjustable population of adults and children. In our tests with a 256 x 256 image, we used population sizes ranging from 30 to 100 for both children and for the parents. In addition, we added a survival policy to recently mutated children to give them a competitive advantage in the testing. That is, some children, regardless of fitness, are spared from the filtering process for an adjustable period of rounds. The intuition behind employing such a policy was to prevent our program from dropping into a local minimum. The only disadvantage of the policy is the sacrificed additional resources that are necessary to keep the less fit offspring alive and allowing them to reproduce.

\subsection{Mutation}
We incorporate multiple levels of mutation to provide for the maximum level of adjustability. At the highest level, we have that each gene which is a stroke can be mutated via addition, editing, or deletion. In the case of addition which has an adjustable rate parameter, we append a completely random new stroke based on the same initial generation parameters to the DNA sequence. Given the opacity parameters, the ordering should not matter. In the case of deletion, we can choose to delete one of the genes or strokes completely from the sequence. Finally, in the case of editing, we can choose to replace the gene with a completely new gene, i.e. addition and deletion combined.
However, we note the mutation for editing may be too drastic and hence, we have a separate level of mutations. Instead of simply changing the entire stroke, we mutate specific attributes of the stroke. This method should prove to be useful when trying to fine tune an image instead of attempting to completely start fresh. We structure the random generation by creating normal distributions centered around the current values for the locations, width, opacity, and color with an adjustable standard deviation. Essentially, instead of randomly guessing with no bias, we attempt to shift the stroke slightly and see if we can find any improvements nearby. Additionally, in this case, we can also choose to remove or add points in the spline of the stroke.

\subsection{Crossovers}
The crossoveres of the DNA were implemented in a couple of methods.

First, the most naive method we chose to use was to pick two DNA strands and we uniformly randomly picked genes or strokes from both strands. Additionally, we pick one strand randomly over the other to determine the length of the strand. However, we expect such a method to yield a random data that does not significantly improve the result. That is, given that a group of strokes together are what most likely cause the fitness to do well as a whole, removing one of these from the group or merging two groups will not necessarily improve the fitness unless they are a large mutually exclusive set.

The other approach we attempt is to swap out entire regions from the DNA strand in an attempt to transfer entire groups of strokes that work well together.

\section{Implementation}
We detail our actual implementation below.
\subsection{Downsampling}
One of the key limitations that we soon realized was the running time required to generate reasonable results. Hence, given these limitations, it would be computationally infeasible to directly apply genetic algorithms to large pictures. However, we can instead reduce the size of the image to a much smaller level that allows for quick processing. After running the algorithm on the less detailed but similar representation, we can enlarge the image to the next level along with the doubling the sizes of the strokes.
Intuitively, this would allow us to determine the general strokes necessary to produce the key features of the picture quickly. The remaining details which would normally take an exorbitant amount of time to be fine tuned would be done much quicker via a narrowed range of mutation as described above. We detail the pseudo code below.

\section{Experiments}
asdf
\section{Results}
asdf
\section{Conclusion}
asdf

\begin{thebibliography}{10}
\bibitem{wang}
Hongling Wang, Joseph Kearney, and Kendall Atkinson, {\em Robust and Efficient Computation of the Closest Point on a Spline Curve}, Dept. of Computer Science, The University of Iowa, (2002).

\bibitem{alsing}
Roger Alsing, {\em Genetic Programming: Evolution of Mona Lisa}, http://rogeralsing.com/2008/12/07/genetic-programming-evolution-of-mona-lisa/.
  
\end{thebibliography}

%----------------------------------------------------------------------------------------

\end{article}

\end{document}